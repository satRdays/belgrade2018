<section id="programme">
<script>
	$(document).ready(function() {
    // Configure/customize these variables.
    var showChar = 200;  // How many characters are shown by default
    var ellipsestext = "...";
    var moretext = "Show more >";
    var lesstext = "Show less";
    

    $('.more').each(function() {
        var content = $(this).html();
 
        if(content.length > showChar) {
 
            var c = content.substr(0, showChar);
            var h = content.substr(showChar, content.length - showChar);
 
            var html = c + '<span class="moreellipses">' + ellipsestext+ '&nbsp;</span><span class="morecontent"><span>' + h + '</span>&nbsp;&nbsp;<a href="" class="morelink">' + moretext + '</a></span>';
 
            $(this).html(html);
        }
 
    });
 
    $(".morelink").click(function(){
        if($(this).hasClass("less")) {
            $(this).removeClass("less");
            $(this).html(moretext);
        } else {
            $(this).addClass("less");
            $(this).html(lesstext);
        }
        $(this).parent().prev().toggle();
        $(this).prev().toggle();
        return false;
    });
});
</script>	
  <h2>Programme</h2>
    <h3>Nadica Miljkovic: Digital biosignal processing with R</h3>
	<div class="more">
	Though R gained high popularity in recent years in areas of data science and bioinformatcss the applicaton of R programming for digital signal processing is not widespread to large extent. Package “Signal” is the most popular CRAN package for signal processing in R. This package contains functons for flterings resamplings interpolaton and other routnes based on traditonal Matlab and GNU Octave functonality.
<br>
Besides “signal”s other useful basic signal processing packages (e.g.s “wavelets”) and specialized packages for digital biosignal processing (e.g.s heart rate variability analysis – “RHRV” packages processing of event-related brain potentals – “erpR”s analysis and evaluaton of electroencephalography data – “eegkit”s routnes for processing and modeling of lectromyography
signals – “biosignalEMG”) provide solid foundaton for R applicaton in digital biosignal processing. 
<br>
In this talk besides brief overview of R for biosignal processings we will demonstrate some useful signal processing techniques implemented in R aiming at artfact cancellaton in biosignals.
	</div>
	
	<h3>Radmila Velickovic: Potentials of R for data linkage</h3>
	<div class="more">
	In the sea of data, matching different datasets and extracting value can be a challenge. I will present available resources in R for deterministic and probabilistic data linkage. Both methods  will be supported with examples.
	</div>
	
	<h3>Radmila Velickovic: Potentials of R for data linkage</h3>
	<div class="more">
	In the sea of data, matching different datasets and extracting value can be a challenge. I will present available resources in R for deterministic and probabilistic data linkage. Both methods  will be supported with examples.
	</div>

	<h3>Sandro Radovanovic: White Box Clustering in R</h3>
	<div class="more">
	Most often we use data mining and machine learning algorithms as black-box, where details are hidden, and the user can optionally play with parameters. I would like to encourage people to use white-box algorithms. In white box algorithms, approach algorithms are disassembled to components which allows deeper understanding and extensibility of an algorithm. This way one can change or add a new component to be better suited for the data at hand. In this talk, WhiBo Clustering package (soon) will be presented with the complete white-box representative based clustering algorithm structure and examples.
	</div>
	
	<h3>Filip Rodik: ETL with R</h3>
<div class="more">
	The standard dilemma when dealing with Extract-Transform-Load tasks is SQL VS graphical piping tools. How does R fit into that? Can time be saved by using R for tedious data wrangling on smaller projects?
</div>

<h3>Marcin Kosinski: Multi-state churn analysis, with the subscription based product</h3>
<div class="more">
	Subscriptions are no longer just for newspapers. The consumer product landscape, particularly among e-commerce firms, includes a bevy of subscription-based business models. Internet and mobile phone subscriptions are now commonplace and joining the ranks are dietary supplements, meals, clothing, cosmetics and personal grooming products.

Standard metrics to diagnose a healthy consumer-brand relationship typically include customer purchase frequency and ultimately, retention of the customer demonstrated by regular purchases. If a brand notices that a customer isn’t purchasing, it may consider targeting the customer with discount offers or deploying a tailored messaging campaign in the hope that the customer will return and not “churn”.

The churn diagnosis, however, becomes more complicated for subscription-based products, many of which offer multiple delivery frequencies and the ability to pause a subscription. Brands with subscription-based products need to have some reliable measure of churn propensity so they can further isolate the factors that lead to churn and preemptively identify at-risk customers.
During the presentation I’ll show how to analyze churn propensity for products with multiple states, such as different subscription cadences or a paused subscription. If the time allows I’ll also present useful plots that provide deep insights during such modeling, that we have developed at <a href="http://gradientmetrics.com/" target="_blank">Gradient Metrics</a> - a quantitative marketing agency.
</div>

<h3>Cervan Girard: Shiny Application - from package development to server deployment</h3>
<div class="more">
	To facilitate our work on shiny applications, we designed a Shiny template included in a R package. Development within a package framework allows for all best practices (vignettes, documentation, tests, etc.) and easier maintenance.
<br>
We will present our tricks and practices to save time in the development of Shiny applications using our {shinytemplate} package. Then, we will show how to deploy the application on a broad scale with Shinyproxy.
</div>

<h3>Peter Laurinec: Time Series Data Mining - from PhD to Startup</h3>
<div class="more">
	The talk will be oriented on differences between "doing" a research and an application of time series data mining to real problems in business on a real rich data.
<br>
I will discuss, why research and business need to be related and also not. Typical tasks of time series data mining in energetics with use cases in R will be shown.
</div>

<h3>Hazel Kavili: Creating Dashboards with Shiny Dashboard</h3>
<div class="more">
	Shiny is an R package that makes it easy to build interactive web apps straight from R. Dashboards are very useful to make insights from your data to make your business grow. In this talk, I’ll give a small intro to creating dashboards by using shiny dashboards and I’ll give examples from my daily use.
</div>

<h3>Mariachiara Fortuna: The full automation - Project and code design for a massive reporting system with R</h3>
<div class="more">
	How to provide a single reporting system to hundreds of different customers? Data sources change, data can contain impurities and output must adapt to different needs. The report must be interactive but remain serverless, and run hundreds of times by itself. In this talk we explore the design needed to bring R at an enterprise level.
</div>

<h3>Ildiko Czeler: The essentials to work with object-oriented systems in R</h3>
<div class="more">
	All R users have used S3, the oldest and most prominent object-oriented system in R even if they were unaware of it, for example by using the summary function both for data frames and for linear models. The two main building blocks of an object-oriented system are objects with specific type (class) and functions (methods) which behave differently depending on the class of their parameters. Most R users probably also had an experience where they got unexpected results which would have been easier to understand with a foundation in object-oriented systems in R. This talk aims to fill some of the gaps so that you can work confidently with existing code utilizing S3 or S4.
<br>
The three widely used object-oriented systems are S3, S4 and R6. This talk will focus on S3 which is the most widely used and assume no prior knowledge of object-oriented systems. I will start with an explanation of the most important concepts and then I will show you how understanding the basics can help you in your day-to-day work.
</div>

<h3>Steven Nooijen: Exploring the world through text analysis</h3>
<div class="more">
	In this session we will explore the world through analysing text in the publicly available Wikivoyage data set. The goal is to introduce a couple of text mining and text analysis techniques, and how they can be implemented in R. Techniques demonstrated will range from textbook TF-IDF, cosine similarity and PCA (Principal Component Analysis) to LDA (Latent Dirichlet allocation) and word embeddings / Word2Vec.
<br>
Special attention will be given to visualizing outcomes of the algorithms. They will help understand concepts behind the applied techniques, and present some funny and/or interesting insights in the way we document about different destinations on our planet.
<br>
Packages used include amongst others `tm`, `SnowballC`, `topicmodels`, `cluster` and of course lot's of `tidyverse`.
</div>

<h3>Lubomir Stepanek: Machine-learning and R in plastic surgery - Classification and attractiveness of facial emotions</h3>
<div class="more">
	Plenty of current studies conclude that human facial attractiveness perception is data-based and irrespective of the perceiver. However, the ways how to analyse associations between facial geometric image data and its visual impact always exceeded the power of classical statistical methods. What is more, current plastic surgery deals with aesthetic indications such as an improvement of the attractiveness of a smile or other facial emotions, therefore it should take into consideration the fact that total face impression is also dependent on presently expressed facial emotion.
<br>
In this work, we have applied machine-learning methods and a power of R language (and some of its packages) to explore how accurate classification of photographed faces into sets of facial emotions and their facial manifestations is, and – furthermore – which facial emotions are associated with higher level of facial attractiveness, measured using Likert scale by a board of independent observers.
<br>
Both profile and portrait facial image data were collected for each of a patient (exposed to an emotion incentive), then processed, landmarked and analysed using R language. The sets of used facial emotions and other facial manifestation originate from Ekman-Friesen FACS scale but were improved substantially. Bayesian naive classifiers using e1071 package, decision trees (CART) via tree and rpart packages and, finally, neural networks by neural net package were learned to allow assigning a new face image data into one of the facial emotions.
<br>
Neural networks manifested the highest predictive accuracy of a new face categorization into facial emotions. The geometrical shape of a mouth, then eyebrows and finally eyes affect in descending order an intensity of a classified emotion, as was identified using decision trees. The mentioned R packages proved their maturity.
<br>
We performed machine-learning analyses to compare which one of classification methods, implemented via R packages, conducts the best prediction accuracy when classifying face images into facial emotions, and – additionally – to point out which facial emotions and geometric features, based on large data evidence, affect facial attractiveness the most, and therefore should preferentially be addressed within plastic surgery procedures.
</div>

<h3>Andjela Todorovic: Markov chain simulation in R</h3>
<div class="more">
	The markovchain package in R is quite an effective tool in creating and analyzing Discrete-Time Markov Chains. In this speech, I will briefly review the underlying theory of Markov chains and it's structural properties. Afterward, I will provide several real-world examples of Markov chains, their implementation in R, and show how to create and manipulate its objects and analyze results.
</div>

<h3>Tamas Nagy: Meta-analysis data management with the {metamanager} package</h3>
<div class="more">
	In the social and medical sciences, researchers often use meta-analysis to aggregate findings from several studies. However, conducting a meta-analysis is a time consuming enterprise, that requires not just domain specific knowledge and analytical experience, but considerable data management skills as well. To aid reproducible research, it should be possible to handle tasks - from collecting to analyzing data - directly in R. Even though there are several useful packages to conduct the statistical part of a meta-analysis, there is a lack of packages that deal with the data management tasks that are typically needed. To fill this gap, we created the {metamanager} package. The package provides several functions for conducting reproducible meta-analysis, while the code remains human readable. Key functionality involves merging and tidying article metadata, flagging duplicates, creating files for human coding, assessing coding performance, detecting and correcting human errors, etc. The package has functions to manage spreadsheets through Google Drive, providing a front-end for manual data entry, access management, version control, and collaborative editing.
</div>

<h3>Viktor Tisza: R for cross-sell modeling</h3>
<div class="more">
	A showcase how R supported cross-sell modeling at Generali. Introduction of the challenges and possible solutions. Meanwhile discovering some useful and fun packages like MLR and Packrat.
</div>

<h3>Steph Locke: SQL Server and R for real-time predictions</h3>
<div class="more">
	Embedding your R (and soon Python!) models in SQL Server enables you to add predictive capabilities to your applications and your analytics without adding expensive components or going outside your network via expensive API calls.
<br>
In this demo-packed talk, you’ll see how you can go from a model built in R to making predictions on the fly in MS SQL Server 2016.
</div>

<h3>Marko Galjak: Using R for Social Network Analysis of Philanthropy - Leveraging Relational Data for Smarter Giving</h3>
<div class="more">
	Using graph theory for solving problems isn’t new. However, increasing amount of data available offers an ever-growing number of opportunities for abstracting the data through graphs. The best-known example of graph abstractions are probably social interactions, however, graph theory can be used to abstract many other concepts. The graph theory is widely used in many disciplines: genomics, business administration, urban planning, environmental studies, social sciences. It has already been widely adopted by security services. Apart from insights network analyses can provide, one of the main reason for its application across so many disciplines is its robustness and scalability which allows for the calculations and clustering to be performed very efficiently even on vast networks.
<br>
Catalyst Balkans is a nonprofit intermediary support organization with a mission to broaden the domestic philanthropy ecosystem in the Western Balkans. Over the past three years, we've been collecting data on philanthropy in the Western Balkans. Our database contains data on more than 30.000 instances of donation classified by a plethora of categories. In our givingbalkans.com application for exploring these data, we built a tool called CiviGraph for the analysis of the relational aspect of our data. In our abstraction donors and beneficiaries are represented by nodes, and the instances of donation are represented as links between them. This abstraction allows for calculating various metrics which can be used in obtaining invaluable intelligence. Further, the visual representation of various neighborhoods formed by donors and beneficiaries can be used to explore the philanthropy landscape in the Western Balkans.
</div>

	
    <!--<script type="text/javascript" src="https://sessionize.com/api/v2/nv454cuz/view/gridtable"></script>-->
    <!--
  <h3>TODO: ??? Friday 22 June - <a href="https://www.meetup.com/Belgrade-R-User-Group/events/251882644/">Pre-conference Social</a></h3>
	<h3>satRday 27 October - Conference</h3>
    <table class="table table-hover">
		<thead>
		  	<tr>
          <th>Start</th>
          <th>End</th>
          <th>VJ Gallery</th>
          <th>Room One (1.122)</th>
          <th>Room Two (1.123)</th>
        </tr>
		</thead>
		<tbody>
		  	<tr>
		    	<td>8:30</td>
		    	<td>9:00</td>
		    	<td><div class="session-title">Registration</div></td>
		  	</tr>
		  	<tr>
		    	<td>9:00</td>
		    	<td>10:30</td>
          <td></td>
		    	<td><div class="session-title">Data Manipulation with dplyr - Kathrine Tansey</div></td>
          <td><div class="session-title">Tidy data science 1 - Steph Locke</div></td>
		  	</tr>
		  	<tr>
		    	<td>10:30</td>
		    	<td>11:00</td>
		    	<td>
		    		<div class="session-title">Tea / Coffee</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>11:00</td>
		    	<td>12:30</td>
          <td></td>
		    	<td><div class="session-title">Upgrade Your Workflow with a Custom Package - Heather Turner</div></td>
          <td><div class="session-title">Tidy data science 2 - Steph Locke</div></td>
		  	</tr>
		  	<tr>
		    	<td>12:30</td>
		    	<td>13:30</td>
		    	<td>
		    		<div class="session-title">Lunch</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>13:30</td>
		    	<td>14:10</td>
          <td></td>
		    	<td><div class="session-title">Introduction to Tidytext - Nujcharee (Ped)</div></td>
          <td><div class="session-title">Snakes in a Package - Adnan Fiaz</div></td>
		  	</tr>
        <tr>
          <td>14:20</td>
          <td>15:00</td>
          <td></td>
          <td><div class="session-title">Our packages reviews in review: introducting and analyzing rOpenSci onboarding system - Maëlle Salmon</div></td>
          <td><div class="session-title">Airtable & R: a marketers heaven - Amy McDougall</div></td>
        </tr>
		  	<tr>
		    	<td>15:00</td>
		    	<td>15:30</td>
		    	<td>
		    		<div class="session-title">Tea / Coffee/ Raffle Draw</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>15:30</td>
		    	<td>16:10</td>
          <td></td>
          <td><div class="session-title">Using Rvest to Collect/Archive Past and Present Daily Financial News - Jack Guangjie Li</div></td>
          <td><div class="session-title">Preparing Your Models For Take Off - Jonathan Stott</div></td>
		  	</tr>
        <tr>
		    	<td>16:20</td>
		    	<td>17:00</td>
          <td></td>
          <td><div class="session-title">Lightning Talks</div></td>
          <td><div class="session-title">Using R to evaluate Smart Meter Energy Data - Ellen Talbot</div></td>
		  	</tr>
        <tr>
		    	<td>17:00</td>
		    	<td>17:30</td>
		    	<td>
		    		<div class="session-title">Closing Session</div>
			    </td>
		  	</tr>
	  	</tbody>
	  </table>

-->
<!--
	<table class="table table-hover">
		<thead>
		  	<tr><th>Start</th><th>End</th><th width="99%" style="text-align: right; color: blue;">Friday 17 February 2017</th></tr>
		</thead>
		<tbody>
		  	<tr>
		    	<td>8:30</td>
		    	<td>10:00</td>
		    	<td>
		    		<div class="session-title">Building and Validating Logistic Regression Models (Steph Locke): Part III</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>10:00</td>
		    	<td>10:30</td>
		    	<td>
		    		<div class="session-title">Coffee</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>10:30</td>
		    	<td>12:00</td>
		    	<td>
		    		<div class="session-title">Shiny (Julia Silge): Part I</div>
		    		<p>Resources:</p>
			  		<ul>
			  			<li> <a href="https://github.com/juliasilge/intro_to_shiny">An Introduction to Shiny</a>
			  			<li> <a href="https://github.com/juliasilge/southafricastats">southafricastats: Population and Mortality Statistics for South Africa</a>
			  		</ul>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>12:00</td>
		    	<td>13:00</td>
		    	<td>
		    		<div class="session-title">Lunch</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>13:00</td>
		    	<td>15:00</td>
		    	<td>
		    		<div class="session-title">Shiny (Julia Silge): Part II</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>15:00</td>
		    	<td>15:30</td>
		    	<td>
		    		<div class="session-title">Coffee</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>15:30</td>
		    	<td>17:00</td>
		    	<td>
		    		<div class="session-title">Shiny (Julia Silge): Part III</div>
			    </td>
		  	</tr>
	  	</tbody>
	  </table>

    <h3>Conference Programme</h3>

    <p>Tutorials are 1 hour long; standard talks are 20 minutes and lightning (<i class="fa fa-flash lightning"></i>) talks are a mere 5 minutes.</p>

    <p>Click on the title for any talk to view the details.</p>

	<table class="table table-hover">
		<thead>
		  	<tr><th>Start</th><th>End</th><th width="99%" style="text-align: right; color: blue;">Saturday 18 February 2017</th></tr>
		</thead>
		<tbody>
		  	<tr>
		    	<td>7:30</td>
		    	<td>8:00</td>
		    	<td><div class="session-title">Early registration for Tutorials</div></td>
		  	</tr>
		  	<tr>
		    	<td>8:00</td>
		    	<td>9:00</td>
		    	<td>
		    		<div class="session-title">Tutorials</div>
		    		<div class="session-talk">
		    			<ul>
							<li class="talk"> Image processing and Tensorflow in R (Raymond Ellis and Greg Streatfield)
								<div class="session-abstract abstract">
								<p>The Nature Conservancy works to preserve marine ecosystems for the future. In November 2016, they asked data scientists to compete at building deep learning algorithms that can detect and classify species of fish from still images. We set out to compete in their competition, using R.</p>

								<p>In this session, we explore how to preprocess and prepare your data for deep learning. We then demonstrate how to use TensorFlow in R to build a solution to the challenge.</p>
								</div>
							<li class="talk"> Redis + R = Multi-user R apps (David Lubinsky) <a href="talks/satRday-2017-lubinsky.pdf"><i class="fa fa-download"></i></a> <a href="talks/satRday-2017-lubinsky.R"><i class="fa fa-download"></i></a>
								<div class="session-abstract abstract">
								<p>There are many options for data persistence from R; from SQL server to Mongo but one option that is fast, powerful, rich and very well suited to R programming  is Redis. The combination of data structures like queues, ordered lists, hash sets with a light in-memory footprint makes Redis the ideal choice for apps that have a high transaction rate, and many users.  In this tutorial, we will show how easy is it is to build R applications with Redis and in particular, how Shiny apps can share back end data through a Redis interface.</p>
								</div>
							<li class="talk"> Shiny / R and Devops (Marko Jakovljevic) <a href="https://view.attach.io/BJlisRYYg"><i class="fa fa-download"></i></a> <a href="https://github.com/OverscoreDev/SatRday2017"><i class="fa fa-github"></i></a>
								<div class="session-abstract abstract">
								<p>Initial background will speak about a DevOps approach to Data science projects showcasing how to use and orchestrate the Docker Container service for Shiny Server / Flask+Bokeh+Pandas (Either Python or R stack).</p>
								<p>Further focus will be on securing the Open Source version of Shiny Server with various approaches including OAuth Implementation such as Auth0.com or custom Authentication (Nginx or Apache Stack).</p>
								<p>Can also share quick and easy Dockerfiles / Containers for Deep Learning / Data Science (Scipy etc.)  which I have built over time to include all the required libraries and code for our Dev Teams.</p>
								</div>
						</ul>
					</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>8:30</td>
		    	<td>9:30</td>
		    	<td>
		    		<div class="session-title">Registration / Coffee</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>9:30</td>
		    	<td>9:40</td>
		    	<td>
		    		<div class="session-title">Welcome & Opening</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>9:40</td>
		    	<td>10:30</td>
		    	<td>
		    		<div class="session-title-left">
		    			Keynote #1: Text mining, the tidy way (Julia Silge)
		    			<a href="https://youtu.be/Xoqs2lNeync"><i class="fa fa-youtube-play"></i></a>
	    			</div>
		    		<div class="sponsor-logo-right"><img src="images/sponsors/derivco.png" height="32px"></div>
		    		<div class="session-chair">Beulah Snyman</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>10:30</td>
		    	<td>11:45</td>
		    	<td>
		    		<div class="session-title-left">Talks (Business Applications of R)</div>
		    		<div class="sponsor-logo-right"><img src="images/sponsors/toptal.png" height="32px"></div>
		    		<div class="session-chair">Jon Calder</div>
		    		<div class="session-talk">
		    			<ul>
							<li class="talk"> Quantitative Strategy Development & Evaluation in R (Jasen Mackie)
								<div class="session-abstract abstract">
								<p>R/quantstrat is an R package built by leaders in the R/Finance community allowing users to efficiently run backtests of trading strategies over multi-asset portfolios. I will run through a basic implementation of the package, and illustrate the tools available for evaluating backtest results, including the R/blotter package.</p>

								<p>For a basic idea of what some of the content will look like you can view Brian Peterson's <a href="https://www.youtube.com/watch?v=8qBo0PqRObU">presentation</a> to the CapeRUser Group which I arranged in July this year. Slides are available <a href="https://braverock.com/brian/CapeR_2016_backtest.html#1">here</a>.</p>

								<p>Depending on the progress I make with the txnsim() R/blotter function by then, I may include it with my talk on evaluating the relative performance of the strategy versus its randomized equivalent with the objective being to assess skill versus luck or overfitting.</p>
								</div>
							<li class="talk"> Visualizing the approach and exceedance of thresholds (Glenn Moncrieff) <i class="fa fa-flash lightning"></i> <a href="talks/satRday-2017-moncrieff.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/xf0nN25_IOc"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>Visualizing thresholds is useful for understanding how they are approached and exceeded, and assisting in planning corrective action. Borrowing from applications in the environmental sciences that have been used to highlight threats to global ecological health, we show how the same technique can be applied to visualize the performance of currency traders.  Six trading rules are used to define thresholds for acceptable trader behaviour. Trading data are analyzed to produce reports aimed at encouraging poorly performing traders to undertake corrective behaviour. Radar plots for the visualization of thresholds are constructed using ggplot2 and the generation of reports with Rmarkdown is automated. A Shiny interface allows traders to easily view and download their personal report. This approach for comparing behaviour to predefined acceptable thresholds is applicable to a wider array of problems beyond trading behaviour or environmental sustainability.</p>
								</div>
							<li class="talk"> R at UBER (Marc van Heerden) <a href="talks/satRday-2017-van-heerden.pdf"><i class="fa fa-download"></i></a>
								<div class="session-abstract abstract">
								<p>An overview of the use cases and workflow employed when using R at UBER. Internal packages are discussed as well as the manner in which R is used in conjunction with other systems to perform ad hoc and scheduled tasks.</p>
								</div>
							<li class="talk"> Rapid Data Science Application Deployment with R Shiny (Nkululeko Thangelane) <i class="fa fa-flash lightning"></i> <a href="talks/satRday-2017-thangelane.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/sHmjn7JUu3U"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>The advantage of using Shiny to Deploy Data Science  Application's.  Showing the flexibility that shiny bring to build complex and simple applications for power  users   and simple users. A call volumes forecasting application will be show cased to show how a powerful app used by business was developed in R Shiny.</p>
								</div>
							<li class="talk"> Who goes there? Profiling street by street audience with Telco data (Kael Huerta) <a href="talks/satRday-2017-huerta.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/Li1R4Z3KH5I"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>This talk shows how to monetize Telco data while respecting users privacy with a street by street profile of the people crossing by. Such profile includes predicting age group, gender, and interests based upon apps usage, web history and passive location (only when the cellphone is used). All implemented in R.</p>
								</div>
							<li class="talk"> Inventory Forecasting using R (Warren Allworth & Peter Gross) <i class="fa fa-flash lightning"></i> <a href="talks/satRday-2017-allworth-gross.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/RWjTK10C4rA"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>Our client required an analytical solution that would assist in optimizing the inventory levels to satisfy customer demand  whilst reducing holding costs and overall footprint in the warehouse. The project focused on using time series analysis for products that exhibited seasonal patterns as well as stochastic modelling for non-seasonal parts (random demand).</p>

								<p>The output of the forecast as well as metadata were then used to determine inventory management thresholds incorporating supplier lead times and order cycles.</p>
								</div>
						</ul>
					</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>11:45</td>
		    	<td>12:45</td>
		    	<td>
		    		<div class="session-title">Lunch</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>12:45</td>
		    	<td>13:35</td>
		    	<td>
		    		<div class="session-title-left">
		    			Keynote #2: Data Rectangling (Jenny Bryan)
		    			<a href="https://youtu.be/GapSskrtUzU"><i class="fa fa-youtube-play"></i></a>
		    		</div>
		    		<div class="sponsor-logo-right"><img src="images/sponsors/r_consortium.png" height="32px"></div>
		    		<div class="session-chair">Alice Coyne</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>13:35</td>
		    	<td>14:40</td>
		    	<td>
		    		<div class="session-title-left">Talks (R in the Sciences)</div>
		    		<div class="sponsor-logo-right"><img src="images/sponsors/uct.jpg" height="32px"></div>
		    		<div class="session-chair">Andrew Collier</div>
		    		<div class="session-talk">
		    			<ul>
							<li class="talk"> Using R for Oceanography (Anne Treasure and Katrin Tirok) <a href="talks/satRday-2017-treasure.pdf"><i class="fa fa-download"></i></a> <a href="talks/satRday-2017-tirok.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/vzXNiYrEWSY"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>Autonomous oceanographic sampling devices such as gliders, Argo floats and animal-borne instruments have become a major component of the ocean observing system and have proven invaluable to the ocean science community. Several steps are involved to get from the raw data to scientific products. While R is not well known or traditionally used in physical oceanography, there are packages and tools available well suited to this field. Seawater characteristics can be calculated from temperature and conductivity using available ocean science R packages such as ‘oce’ or ‘gsw'. ‘Oce’ can also be used to plot data density distribution maps. For subsequent analyses, statistical and geostatistical packages for R are helpful, e.g. kriging of variables for spatial interpolation using ‘gstat’. Packages such as ‘ggplot’ and ‘ggmap' are useful for the visualisation of data in the form of contour plots and current velocities.</p>

								<p>Here, we will showcase these uses of R for oceanography by highlighting results from two research studies where data from autonomous oceanographic sampling devices have been used. The successful use of autonomous devices can depend on the study region of interest. Therefore, we will first show results of a spatial and temporal comparison of data from Argo floats and animal-borne instruments in the Southern Ocean along with some functionality of the package ‘oce’. Second, a more in depth look at subsequent analysis of data will be shown, using data from gliders in the Agulhas current off Northern KwaZulu-Natal.</p>
								</div>
							<li class="talk"> Impact of fishing on African penguin population off the West Coast (Andrea Ross-Gillespie) <i class="fa fa-flash lightning"></i> <a href="talks/satRday-2017-ross-gillespie.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/pd269xRsSs4"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>The African Penguin population has been declining steadily, likely as a result of dramatic changes in the anchovy and sardine abundances, as these species form the primary component of the penguins' diets. In 2008, an experiment was initiated  whereby an area of a 10nm radius around each of four selected breeding islands (Dassen and Robben islands on the West Coast, and Bird and St Croix on the South Coast) was closed to the fishery. The aim of the experiment is to see whether the fishing activity around the breeding island has a negative impact on the penguin population, or conversely whether closing the island to the fishery benefits the penguins in a meaningful way.</p>

								<p>Analysis of the collected penguin population data however did not yield conclusive results, leading to the question of whether or not the experiment should continue. The challenge is to balance (on the one hand) the risk of concluding that there is no meaningful impact on the penguin population when in fact there is an impact that has just not been detected yet in the data, and (on the other hand) continuing the closure experiment when there is in fact no meaningful beneficial impact on the penguin population, at a great cost to the fishing industry.  To address this challenge, we embarked on a form of a power analysis, which aims to answer the following question: If there is a biologically meaningful impact of the fishery on the penguin population, how long would the island closure experiment need to continue for before we are likely to detect this impact?</p>

								<p>This question, and the way to address it, has been the discussion of the International Stock Assessment Workshop held at UCT over the last two years. The work was concluded in December 2016, with the final recommendations by the panel for the workshop leading to the analyses presented at a recent working group meeting of the Fisheries Branch of the Department of Agriculture, Forestry and Fisheries to inform the decision on the future of the penguin island closure experiment.</p>
								</div>
							<li class="talk"> MicRobiome ​Analysis (Katie Lennard and Kirsty Lee Garson) <a href="talks/satRday-2017-lennard-garson.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/XE3EyLem9s4"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>More than half of the cells which make up our bodies are bacterial. The human body is home to a diverse array of bacteria and other microorganisms, collectively known as the human microbiome. Alterations in the microbiome have been linked to a wide variety of diseases including cancer, asthma, obesity, and depression.</p>

								<p>Over the last decade​, recent advances in DNA sequencing technology have​ facilitated rapid progress​​ in microbiome research, which has been met with the equally rapid ​development ​of​ data analysis methods - many of which are implemented in R.</p>

								<p>Here we briefly introduce R-based microbiome analysis, using the role of the microbiome in HIV susceptibility as an example. Creating graphics in R for high dimensional data serves as a first step in data exploration. As an example, we will demonstrate the use of annotated heatmaps, a versatile tool with a wide range of applications.</p>
								</div>
							<li class="talk"> Visual modelling with pavo (Jeroen van der Merwe) <i class="fa fa-flash lightning"></i> <a href="talks/satRday-2017-van-der-merwe.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/wPBkiEYkIs4"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>Using the package pavo we created visual models to obtain distances in visual space between populations of restio leaf hoppers. Shorter distances in visual space showing closer matches in colour. This formed part of a study to see whether local adaptation of leaf hoppers to local host plants has occurred.</p>
								</div>
							<li class="talk"> Helping to ease the pain with R/RMarkdown (Peter Kamerman) <i class="fa fa-flash lightning"></i> <a href="talks/satRday-2017-kamerman.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/ZXt-7AfnR4M"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>We recently submitted an application to the World Health Organisation for the inclusion of a medicine (gabapentin) used to manage pain caused by nerve damage on its 'List of Essential Medicines'. Wanting to make the the process of generating the report as transparent and reproducible as possible, we decided to give R/RMarkdown a try. Using these tools, sprinkled with bits of LaTeX that had to learn on on the fly, we generated the full application, a supplementary <a href="https://painblogr.org/neuropathic-pain-storyboard-2016/">online storyboard</a>, and made all the code and data <a href="https://kamermanpr.github.io/WHO-EML-application-2016/">available online</a>. I will present some of the cool data on the burden of chronic pain (especially neuropathic pain) and analgesic medicine availability that we pulled together from various sources, and how we used R and some of the many static and interactive plotting tools available in the R ecosystem to analyse and visualise these data in a meaningful and (hopefully) compelling manner.</p>
								</div>
							<li class="talk"> Prospects for Trachoma Elimination through targeted mass treatment (Laing Lourens) <i class="fa fa-flash lightning"></i> <a href="talks/satRday-2017-lourens.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/IxoAt_AunP8"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>Trachoma is the worldwide leading infectious cause of blindness. Nearly 20 years ago, the World Health Organisation (WHO) issued the goal of eliminating trachoma induced blindness by the year 2020. Previous evidence has shown that targeted treatment to children less than 10 years of age is able to reduce prevalence across an entire community.</p>

								<p>A Markov model of trachoma transmission that assumes two age classes is presented, with parameters estimated using an accept/reject procedure fitted to data from a previous clinical trial. Based on the best fitting parameter sets, mass drug administration at different coverage and periodicity is simulated to assess its impact on population level prevalence.</p>
								</div>
							<li class="talk"> Using R to understand Human Evolution (Kerryn Warren) <i class="fa fa-flash lightning"></i> <a href="talks/satRday-2017-warren.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/DFOdbXwG8o0"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>The hominin (human) fossil record is scant, and palaeoanthropologists frequently rely on a variety of specialised programmes to make sense of our own evolution. R, however, has allowed for the integration of a variety of techniques, such as collecting data on 3D scans, analysing morphological and GIS data and producing effective figures for interpretation of trends.</p>

								<p>The trend towards using R for analysing fossil records has allowed for greater collation of techniques (internationally) and more openness with results.</p>
								</div>
						</ul>
					</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>14:40</td>
		    	<td>15:10</td>
		    	<td>
		    		<div class="session-title">Coffee</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>15:10</td>
		    	<td>16:00</td>
		    	<td>
		    		<div class="session-title-left">
		    			Keynote #3: The you in community (Stephanie Locke)
		    			 <a href="https://youtu.be/vqP2uTYOWK4"><i class="fa fa-youtube-play"></i></a>
	    			</div>
		    		<div class="sponsor-logo-right"><img src="images/sponsors/ixperience.png" height="32px"></div>
		    		<div class="session-chair">Katie Lennard</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>16:00</td>
		    	<td>17:20</td>
		    	<td>
		    		<div class="session-title-left">Talks (General)</div>
		    		<div class="sponsor-logo-right"><img src="images/sponsors/microsoft.jpg" height="32px"></div>
		    		<div class="session-chair">Etienne Koen</div>
		    		<div class="session-talk">
		    			<ul>
							<li class="talk"> Microsoft, Open Source, R: You gotta be kidding! (Niels Berglund) <a href="talks/satRday-2017-berglund.pdf"><i class="fa fa-download"></i></a> <a href="https://www.nielsberglund.com/2017/02/25/microsoft-r-server/"><i class="fa fa-rss"></i></a> <a href="https://youtu.be/tYNPhFyDFd4"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>In this talk we will have a look at Microsoft R Server, which is a High Performance Computing  and a High Performance Analytics R implementation. The talk is highly code-driven, and we will do comparisons between CRAN R amd the Microsoft implementation.</p>
								</div>
							<li class="talk"> R and PowerBI: best frenemies (Michael Johnson) <i class="fa fa-flash lightning"></i> <a href="talks/satRday-2017-johnson.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/HOEQifGXCR8"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>For many years, there has been a rivalry between Microsoft and the open source community but that is changing. PowerBI is Microsoft’s new data tool that allows data analysts to create rich interactive reports with support for data preparation, modeling, and visualization and now includes R integration.</p>

								<p>In this session, we'll look at how PowerBI and R integrate using R scripts allowing the data analyst to leverage the strengths of each tool.</p>
								</div>
							<li class="talk"> High performance R: integrating cpp into your workflow (Robert Bennetto) <a href="talks/satRday-2017-bennetto.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/IIa2FM1C84U"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>The talk will provide motivations to integrating cpp into your workflow as a data scientist - the result of which can dramatically improve the overall performance of your R code. A brief discussion of the R interpreter and a comparison to compiled languages will be provided with examples to substantiate the motivation.</p>

								<p>The types of computational tasks that lend themselves to a cpp approach will be discussed. An overview of the cpp primitives available out-the-box is provided.</p>
								</div>
							<li class="talk"> Using visNetworks to Visualize Vine Copula (Hanjo Odendaal) <i class="fa fa-flash lightning"></i> <a href="https://youtu.be/XFKTWuiYV0o"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>Currently the visual illustration of Vine copulae from the VineCopula package offers a bland plotting output. Combining the visNetwork html-widget along with the VineCopula RVM output, offers an interactive and visually appealing way to understand to interpret your output.</p>
								</div>
							<li class="talk"> R as a GIS: Introduction to spatial data visualization and manipulation (Jacques Booysen) <a href="talks/satRday-2017-booysen.pdf"><i class="fa fa-download"></i></a> <a href="https://www.youtube.com/watch?v=elurnkEN4Dw"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>This talk is an introduction to using spatial data in R, giving an overview as well as practical application of how spatial data can be created, manipulated and visualised using the R platform.It assumes no prior knowledge of spatial data analysis but prior understanding of the R command line would be beneficial. Practical applications will include: using the Google Elevation API with Google Maps Visualization using R, Spatial Interpolation/Modeling of Temperature Data in R and GIS climate change data on Amazon S3 using R.</p>
								</div>
							<li class="talk"> Energy planning for climate change using R, StarCluster and Shiny (Schalk Heunis) <i class="fa fa-flash lightning"></i> <a href="talks/satRday-2017-heunis.pdf"><i class="fa fa-download"></i></a> <a href="https://www.youtube.com/watch?v=AaEPmk79qX4"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>StarCluster is an open source grid computing framework that was used with R and Shiny to produce a geospatial visual interactive dashboard to inform energy planners about the long term impact of climate change on energy supply in Africa.</p>

								<p>StarCluster runs on Amazon EC2 and allowed horizontal scaling of MIP optimization.  We were able to produce optimal energy solutions over thousands of future climate/socio-economic scenarios and decision.  These solutions are then presented to decision makers who can interact with the dashboard to build intuition, understand risks and discover opportunities.</p>

								<p>This talk is about using horizontal scaling to deal with uncertainty in decision making using R, Shiny and StarCluster on Amazon EC2.</p>
								</div>
							<li class="talk"> Open Data for Better Decision Making (Matthew Adendorff) <i class="fa fa-flash lightning"></i> <a href="talks/satRday-2017-adendorff.pdf"><i class="fa fa-download"></i></a> <a href="https://youtu.be/e7AGza_sDq8"><i class="fa fa-youtube-play"></i></a>
								<div class="session-abstract abstract">
								<p>We live in the Data Age and now have the ability to ingest huge quantities of information to power predictions and insights. A caveat to this new-found computational capacity is that the adage, <em>Garbage in, garbage out</em>, is still as relevant as ever, if not more so. In addition, the distillation of meaningful information from the Internet's data fire-hose takes careful processing and reduction; and a well-manicured dataset is worth its weight in gold.</p>

								<p>Fortunately, in tandem with this current rise in access to information, the open data movement is rapidly approaching maturation and governments / civic society are now providing powerful tools and insight-rich data repositories free-of-charge to whomever wants to utilize them. The inclusion of such sources and technologies in modern <em>Big Data</em> infrastructure can provide a powerful platform for impactful analyses.</p>

								<p>In this talk I will present the potential that these open data sources present for modern computational pipelines, and will discuss some successful applications of this paradigm to South African challenges.</p>
								</div>
						</ul>
					</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>17:20</td>
		    	<td>17:30</td>
		    	<td>
		    		<div class="session-title">Break</div>
			    </td>
		  	</tr>
		  	<tr>
		    	<td>17:30</td>
		    	<td>18:00</td>
		    	<td>
		    		<div class="session-title-left">Data Visualisation Challenge</div>
		    		<div class="sponsor-logo-right"><img src="images/sponsors/vantage-data.png" height="32px"></div>
		    		<div class="session-chair">Ryan Nel</div>
			    </td>
		  	</tr>
		</tbody>
  	</table>
  	-->
</section>
